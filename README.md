# **Machine Learning Engineer** â€“ **Backend Developer**  

Expertise in developing advanced NLP, speech and computer vision models, fine-tuning LLMs, and deploying scalable backend systems. Proven track record of delivering innovative solutions to complex challenges in data processing and AI applications.  

**Tehran** | **+989213207541** | **razitmazinani@gmail.com** | [LinkedIn: razi-taj-mazinani](https://linkedin.com/in/razi-taj-mazinani) | [GitHub: razi-tm](https://github.com/razi-tm)  

---

## **Skills**  

### **Deep Learning - Machine Learning**  
- PyTorch, TensorFlow, Keras, Fastai, LAVIS, YOLO, Scikit-Learn, OpenCV  

### **Algorithms**  
- Familiar with:  
  - Dynamic programming, Memoization, Divide and conquer, Greedy, Sorting, Binary search  
  - Uninformed search strategies (Breadth-first search, Depth-first search, Uniform-cost search, Depth-limited search, Iterative deepening search)  
  - Informed search strategies (Greedy, A*)  
  - Local search (Hill climbing, Simulated annealing, Genetic algorithm)  
  - Adversarial search (Minimax, Alpha-beta pruning)  
  - Several indexing algorithms for similarity search  

### **Data Analytics**  
- Numpy, Pandas, Matplotlib  

### **Programming Languages**  
- Python, C/C++  

### **Hardware Assembly and Configuration**  
- Assembling machine learning stations  

### **Other**  
- Linux, Git, Docker, Django, ElasticSearch, FAISS, PostgreSQL, Pgvector, Google Colab, Advanced VPN setup  

### **English**  
- Full professional efficiency  

---

## **Work Experience**  
- **Machine Learning Engineer - Backend Developer** at Sharif Search  
- **Machine Learning Engineer (Internship)** at Sharif Search  

---

## **Soft Skills**  
- Problem-solving and critical thinking  
- Communication and collaboration in cross-functional teams  
- Time management and prioritization  
- Creative thinking and innovation  
- Adaptability and resilience in fast-paced environments  
- Attention to detail and quality assurance  
- Interpersonal skills for stakeholder engagement  
- Curiosity and continuous learning  

---

## **Projects**  

### **Building a Very Large Persian Dataset for Fine-Tuning LLMs**  
- A massive Persian dataset in question-answering format, including 50k samples and around 200k lines, tailored for NLP tasks.  

### **Fine-Tuning a Large Language Model**  
- Fine-tuned Llama 3 using the dataset mentioned above. Enabled the model to understand and generate Persian text, overcoming its limitations for handling the Persian language.  

### **Retrieval Augmented Generation (RAG)**  
- Developed a system that combines information retrieval and generative AI to improve the accuracy and relevance of generated text by leveraging external datasets.  

### **Speech-to-Text**  
- Implemented a robust pipeline for converting spoken language to written text with high accuracy, optimized for noisy environments.  

### **Speaker Identification**  
- Designed and deployed a deep learning-based system to identify and distinguish speakers.  

### **Noise Reduction Using Deep Learning**  
- Applied advanced neural networks to remove noise from audio signals, achieving superior clarity and fidelity.  

### **Open-Source Contributor ([Pyannote.Audio](https://github.com/pyannote/pyannote-audio))**  

### **Text-to-Speech**  

### **Image Similarity Search**  
- Developed a fast and scalable image similarity search engine using embeddings.  

### **Face Recognition with Increased Speed Using a Creative Method**  
- Innovated on traditional algorithms to accelerate face recognition tasks while maintaining high accuracy, optimized for large-scale datasets.  

### **Object Detection**  

### **Image Captioning**  

### **Text Summarization**  

### **Spell Checker**  

### **Local Implementation of Translation Models**  

### **Optical Character Recognition (OCR)**  

### **Customized Scraper for a Specific Website**  

### **Handling Big Data Using PostgreSQL**  
- Implemented data management strategies utilizing PostgreSQL to efficiently store, query, and analyze large datasets. Leveraged its advanced features, like indexing, to optimize performance and ensure scalability in data processing.  

**Deployment:** Dockerized and deployed projects for production, ensuring scalability, reliability, and ease of integration when required.  
